<!DOCTYPE html>
<html>
<head> 
	<meta charset="utf-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="stylesheet.css">
	<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">
	<script type="text/javascript">

	//variable declarations
	var fft_size = 2048;	//om vi ökar fftSize till 4096 bli det bättre beräkningar (får upp låga frekvenser) eller långsammare?

	//skapar vår context och dess noder
	var audio_context = new AudioContext();
	var analyser = audio_context.createAnalyser();
	var gain_node = audio_context.createGain();

	var C2 = 65.41; // C2 note, in Hz.
	var notes = [ "C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B" ];
	var test_frequencies = [];

	//för varje not skapas en frekvens där noten faktiskt ska va, en frekvens där den säger att den är för låg, och en frekvens där den är för hög. dessa tre frekvenser för varje ton läggs i arrayen test_frequencies i sorterad ordning.
	for (var i = 0; i < 30; i++)
	{
		var note_frequency = C2 * Math.pow(2, i / 12); //dess riktiga frekvenser
		var note_name = notes[i % 12];	//tillhörande namn från notes-arrayen
		var note = { "frequency": note_frequency, "name": note_name }; //skapar ett objekt
		var just_above = { "frequency": note_frequency * Math.pow(2, 1 / 48), "name": note_name + " (a bit sharp)" }; //den för höga frekvensen är riktiga frekvensen gånger 2^(1/48)
		var just_below = { "frequency": note_frequency * Math.pow(2, -1 / 48), "name": note_name + " (a bit flat)" };
		test_frequencies = test_frequencies.concat([ just_below, note, just_above ]);
	}


	window.addEventListener("load", initialize); //när load (sidan öppnar) så sätts initialize funktionen igåg
	var correlation_worker = new Worker("correlation_worker.js");
	correlation_worker.addEventListener("message", interpret_correlation_result); //när message kommer från correlation_worker.js så sätts interpret_correlation_result igång


	//initialize access to microphone 
	function initialize(){

		console.log("inne i initialize");

		var getMicrophone = navigator.getUserMedia;
		getMicrophone = getMicrophone || navigator. webkitGetUserMedia || navigator. mozGetUserMedia;
		//moz for firefox and webkit for crome and others

		// vi vill bara ha tillgång till ljudet och om tillåts så vill vi köra funktionen use_stream.
		getMicrophone.call(navigator, {"audio": true}, use_stream, function() {});

	}




	//input parameter stream since it's the microphone
	function use_stream (stream){

		console.log("inne i use_stream");
		analyser.fftSize = fft_size;

		var mic = audio_context.createMediaStreamSource(stream);

		gain_node.gain.value = 0;

		//kopplar noderna i contexten till varandra och sedan ut.
		mic.connect(analyser);
		analyser.connect(gain_node);
		gain_node.connect(audio_context.destination);

		loop();

	}

	function loop(){

		var buffer = new Float32Array(analyser.fftSize); 
		analyser.getFloatTimeDomainData(buffer); //fyller buffern med våg-datan från ljudet som kommer in i analys-noden
		console.log(buffer);

		//skickar message till correlation_worker
		correlation_worker.postMessage({

			"timeseries": Array.prototype.slice.call(buffer), "test_frequencies": test_frequencies, "sample_rate": audio_context.sampleRate

		});

	}



	function interpret_correlation_result (event) {

	console.log("inne i interpret");

		var timeseries = event.data.timeseries; //fortfarande vår mic-ljud-kurva som värden i en array
		var frequency_amplitudes = event.data.frequency_amplitudes; //array med amplituderna(likheten) mellan micljudet och varje testfrekvens


		// Compute the (squared) magnitudes of the complex amplitudes for each
		// test frequency.
		//räknar om frequency_amplitudes från [re, im]-objekt till ett valigt tal, typ, och sparar i
		//array magnitudes
		var magnitudes = frequency_amplitudes.map(function(z) { return z[0] * z[0] + z[1] * z[1]; });

		// Find the maximum in the list of magnitudes.
		var maximum_index = -1; //bara ett värde liksom, finns ingen plats i en array som har -1
		var maximum_magnitude = 0; // också ett värde som kommer bytas ut
		for (var i = 0; i < magnitudes.length; i++)
		{
			//om skillnaden är mindre än max så fortsätt jämför(nästa itteration)
			if (magnitudes[i] <= maximum_magnitude) 
				continue;
			//annars har vi hittat ett nytt max och dess plats i magnitudes-arrayen(och även test-frekvens-arrayen)
			maximum_index = i;
			maximum_magnitude = magnitudes[i];
		}

		// Compute the average magnitude. We'll only pay attention to frequencies
		// with magnitudes significantly above average.

		// "The reduce() method applies a function against an accumulator and each value of the array (from left-to-right) to reduce it to a single value." Lägger alltså ihop alla värden i arrayen och delar på arrayens längs, som man räknar ut meddelvärde i allmännhet.
		var average = magnitudes.reduce(function(a, b) { return a + b; }, 0) / magnitudes.length;
		
		//confidence, som i att vi är säkra på att denna magnitude står ut från meddelvärdet eftersom vi bara vill ha de frekvenser vi är säkra på.
		var confidence = maximum_magnitude / average;
		var confidence_threshold = 10; // empirical, arbitrary.
		//om vi är säkra så hittar vi rätt plats i test-frekvens-arrayen och hämtar dess objekt attribut
		if (confidence > confidence_threshold)
		{
			var dominant_frequency = test_frequencies[maximum_index];
			document.getElementById("note-name").textContent = dominant_frequency.name;
			document.getElementById("frequency").textContent = dominant_frequency.frequency;
		}

		setTimeout(loop, 250); //efter 250 millisekunder tar vi upp ett nytt mic-sljud-sample (dvs 4ggr i sekunden)

	}	

	//HÄR SLUTAR KODEN FÖR CORRELATIONBERÄKNINKARNA (och det därtill)

	var tones = ["E", "A", "D", "G", "B", "E"];
	var text = "";
	var i;
	for(i = 0; i < 6; i++)
	{
		text += tones[i] + " ";
	}

	var c = document.getElementById("myCanvas");
	var ctx = c.getContext("2d");
	ctx.font = "40px Arial";
	ctx.fillStyle = "#FF4719";

	
	function currentTone(tone, freq) 
	{
		document.getElementById("icon-up").style.color = "#a9a9a9";
		document.getElementById("icon-down").style.color = "#a9a9a9";
		if(freq > 10)
		{
			document.getElementById("icon-up").style.color = "#313131";
		}
		else
		{
			document.getElementById("icon-down").style.color = "#313131";
		}
		for(var i = 0; i < 6; i++)
		{
			if(tone == i)
			{
				ctx.clearRect(0, 0, 100, c.height);
				ctx.fillText(tones[i], 36, 60);
				break;
			}
		}

		document.getElementById("currFreq").innerHTML = tone;
		
	}
	</script>
</head>

<body>

	<div class ="col-12">
	<p id = "title"> GUITAR TUNER  <sub><i class="fa fa-music"></i></sub></p>
	<hr class = "default">
	<p id = "about"> 
	A Guitar Tuner made for the course TFYA65 at Linköping University <br>
	Made by Kristin Bäck, Karin Reidarman, Sara Martin.
	</p>
	
	<p id = "tones"> </p>

	<div class ="col-4 down">
	<i id = "icon-down" class="fa fa-3x fa-chevron-down text-default"></i>
	</div>
	<div class ="col-4">
	<canvas id = "myCanvas" width = "100" height = "100"> 
	</canvas> 
	</div>
	<div class ="col-4 up">
	<i id = "icon-up" class="fa fa-3x fa-chevron-up text-default"></i> 
	</div>

	<br>
	<p id = "about"> Current Frequency: </p>
	<p id ="currFreq"> </p>

	</div>

	<!-- Script part of UI -->
	<script>
	
	</script>
	
</body>

</html>

